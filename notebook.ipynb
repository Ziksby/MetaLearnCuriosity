{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_disable_jit\", False)\n",
    "# jax.config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A Google TPU may be present on this machine, but either a TPU-enabled jaxlib or libtpu is not installed. Falling back to cpu.\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Taken from:\n",
    "# https://github.com/corl-team/xland-minigrid/blob/main/training/train_single_task.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gymnax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util\n",
    "import optax\n",
    "import wandb\n",
    "from flax.jax_utils import replicate, unreplicate\n",
    "from flax.training.train_state import TrainState\n",
    "import distrax\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from MetaLearnCuriosity.agents.nn import AtariBYOLPredictor, BYOLEncoder, BYOLTarget, OpenScannedRNN, CloseScannedRNN\n",
    "from MetaLearnCuriosity.checkpoints import Save\n",
    "from MetaLearnCuriosity.logger import WBLogger\n",
    "from MetaLearnCuriosity.utils import BYOLTransition as Transition\n",
    "from MetaLearnCuriosity.utils import byol_normlise_prior_int_rewards,  BYOLRewardNorm\n",
    "from MetaLearnCuriosity.utils import (\n",
    "    make_obs_gymnax_discrete,\n",
    "    process_output_general,\n",
    ")\n",
    "from MetaLearnCuriosity.wrappers import (\n",
    "    FlattenObservationWrapper,\n",
    "    LogWrapper,\n",
    "    VecEnv,\n",
    ")\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "from typing import Sequence, TypedDict\n",
    "import functools\n",
    "import math\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "import distrax\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "environments = [\n",
    "    \"Asterix-MinAtar\",\n",
    "    # \"Breakout-MinAtar\",\n",
    "    # \"Freeway-MinAtar\",\n",
    "    # \"SpaceInvaders-MinAtar\",\n",
    "]\n",
    "config = {\n",
    "    \"RUN_NAME\": \"minatar_baseline_ppo\",\n",
    "    \"SEED\": 42,\n",
    "    \"NUM_SEEDS\": 2,\n",
    "    \"LR\": 5e-3,\n",
    "    \"NUM_ENVS\": 64,\n",
    "    \"NUM_STEPS\": 128,\n",
    "    \"TOTAL_TIMESTEPS\": 1e5,\n",
    "    \"UPDATE_EPOCHS\": 4,\n",
    "    \"NUM_MINIBATCHES\": 8,\n",
    "    \"GAMMA\": 0.99,\n",
    "    \"GAE_LAMBDA\": 0.95,\n",
    "    \"CLIP_EPS\": 0.2,\n",
    "    \"ENT_COEF\": 0.01,\n",
    "    \"VF_COEF\": 0.5,\n",
    "    \"MAX_GRAD_NORM\": 0.5,\n",
    "    \"ACTIVATION\": \"relu\",\n",
    "    \"ANNEAL_LR\": True,\n",
    "    \"DEBUG\": False,\n",
    "    \"PRED_LR\": 1e-4,\n",
    "    \"ENCODER_LR\": 1e-4,\n",
    "    \"EMA_PARAMETER\": 0.99,\n",
    "    \"REW_NORM_PARAMETER\": 0.99,\n",
    "    # \"INT_LAMBDA\": 0.006,\n",
    "}\n",
    "\n",
    "class PPOActorCritic(nn.Module):\n",
    "    action_dim: Sequence[int]\n",
    "    activation: str = \"tanh\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        if self.activation == \"relu\":\n",
    "            activation = nn.relu\n",
    "        else:\n",
    "            activation = nn.tanh\n",
    "\n",
    "        actor_mean = nn.Dense(64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0))(\n",
    "            x\n",
    "        )\n",
    "        actor_mean = activation(actor_mean)\n",
    "        actor_mean = nn.Dense(\n",
    "            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\n",
    "        )(actor_mean)\n",
    "        pi = distrax.Categorical(logits=actor_mean)\n",
    "\n",
    "        critic = nn.Dense(64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0))(x)\n",
    "        critic = activation(critic)\n",
    "        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(critic)\n",
    "\n",
    "        return pi, jnp.squeeze(critic, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config_env(config, env_name):\n",
    "    config[\"ENV_NAME\"] = env_name\n",
    "    num_devices = jax.local_device_count()\n",
    "    assert config[\"NUM_ENVS\"] % num_devices == 0\n",
    "    config[\"NUM_ENVS_PER_DEVICE\"] = config[\"NUM_ENVS\"] // num_devices\n",
    "    config[\"TOTAL_TIMESTEPS_PER_DEVICE\"] = config[\"TOTAL_TIMESTEPS\"] // num_devices\n",
    "    # config[\"EVAL_EPISODES_PER_DEVICE\"] = config[\"EVAL_EPISODES\"] // num_devices\n",
    "    config[\"NUM_UPDATES\"] = (\n",
    "        config[\"TOTAL_TIMESTEPS_PER_DEVICE\"] // config[\"NUM_STEPS\"] // config[\"NUM_ENVS_PER_DEVICE\"]\n",
    "    )\n",
    "    config[\"MINIBATCH_SIZE\"] = (\n",
    "        config[\"NUM_ENVS_PER_DEVICE\"] * config[\"NUM_STEPS\"] // config[\"NUM_MINIBATCHES\"]\n",
    "    )\n",
    "    config[\"TRAINING_HORIZON\"] = (\n",
    "        config[\"TOTAL_TIMESTEPS_PER_DEVICE\"] // config[\"NUM_ENVS_PER_DEVICE\"]\n",
    "    )\n",
    "    env, env_params = gymnax.make(config[\"ENV_NAME\"])\n",
    "    env = FlattenObservationWrapper(env)\n",
    "    env = LogWrapper(env)\n",
    "    env = VecEnv(env)\n",
    "\n",
    "    return config, env, env_params\n",
    "\n",
    "\n",
    "def ppo_make_train(rng):\n",
    "    def linear_schedule(count):\n",
    "        frac = (\n",
    "            1.0\n",
    "            - (count // (config[\"NUM_MINIBATCHES\"] * config[\"UPDATE_EPOCHS\"]))\n",
    "            / config[\"NUM_UPDATES\"]\n",
    "        )\n",
    "        return config[\"LR\"] * frac\n",
    "\n",
    "    # INIT NETWORK\n",
    "    network = PPOActorCritic(env.action_space(env_params).n, activation=config[\"ACTIVATION\"])\n",
    "    pred = AtariBYOLPredictor(64, env.action_space(env_params).n)\n",
    "    target = BYOLTarget(64)\n",
    "    encoder = BYOLEncoder(64)\n",
    "\n",
    "    # KEYS\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    rng, _tar_rng = jax.random.split(rng)\n",
    "    rng, _en_rng = jax.random.split(rng)\n",
    "    rng, _pred_rng = jax.random.split(rng)\n",
    "\n",
    "    #INPUTS \n",
    "    init_x = jnp.zeros((1,config[\"NUM_ENVS_PER_DEVICE\"],*env.observation_space(env_params).shape))\n",
    "    init_en_x = jnp.zeros((1,config[\"NUM_ENVS_PER_DEVICE\"],64))\n",
    "    action = jnp.zeros((1,config[\"NUM_ENVS_PER_DEVICE\"]), dtype=jnp.int32)\n",
    "    open_init_hstate = OpenScannedRNN.initialize_carry(config[\"NUM_ENVS_PER_DEVICE\"], 16)\n",
    "    close_init_hstate = CloseScannedRNN.initialize_carry(config[\"NUM_ENVS_PER_DEVICE\"], 16)\n",
    "    init_bt = jnp.zeros((1,config[\"NUM_ENVS_PER_DEVICE\"],16))\n",
    "    init_input=(init_bt,init_en_x,action)\n",
    "\n",
    "    #PARAMS\n",
    "    network_params = network.init(_rng, init_en_x)\n",
    "    target_params = target.init(_tar_rng, init_x)\n",
    "    encoder_params = encoder.init(_en_rng, init_x)\n",
    "    pred_params = pred.init(_pred_rng, close_init_hstate, open_init_hstate,init_input)\n",
    "\n",
    "    if config[\"ANNEAL_LR\"]:\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.adam(learning_rate=linear_schedule, eps=1e-5),\n",
    "        )\n",
    "    else:\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.adam(config[\"LR\"], eps=1e-5),\n",
    "        )\n",
    "    pred_tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.adam(config[\"PRED_LR\"], eps=1e-5),\n",
    "    )\n",
    "    en_tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.adam(config[\"ENCODER_LR\"], eps=1e-5),\n",
    "    )\n",
    "    train_state = TrainState.create(\n",
    "        apply_fn=network.apply,\n",
    "        params=network_params,\n",
    "        tx=tx,\n",
    "    )\n",
    "    pred_state = TrainState.create(\n",
    "        apply_fn = pred.apply,\n",
    "        params = pred_params,\n",
    "        tx=pred_tx,\n",
    "    )\n",
    "    encoder_state = TrainState.create(\n",
    "        apply_fn = encoder.apply,\n",
    "        params = encoder_params,\n",
    "        tx=en_tx,\n",
    "    )\n",
    "\n",
    "    rng = jax.random.split(rng, jax.local_device_count())\n",
    "\n",
    "    return rng, train_state, pred_state, encoder_state, target_params,close_init_hstate,open_init_hstate, init_bt\n",
    "\n",
    "\n",
    "def train(rng, train_state, pred_state, encoder_state, target_params,close_hstate,open_hstate,bt):\n",
    "    target=BYOLTarget(64)\n",
    "    byol_reward_norm_params = BYOLRewardNorm(0,0,1,0)\n",
    "    # INIT ENV\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    reset_rng = jax.random.split(_rng, config[\"NUM_ENVS_PER_DEVICE\"])\n",
    "    obsv, env_state = env.reset(reset_rng, env_params)\n",
    "\n",
    "    update_target_counter = 0\n",
    "    # TRAIN LOOP\n",
    "    def _update_step(runner_state, unused):\n",
    "        # COLLECT TRAJECTORIES\n",
    "        \n",
    "        def _env_step(runner_state, unused):\n",
    "            train_state,pred_state,encoder_state,target_params, close_hstate,open_hstate,bt, byol_reward_norm_params,env_state, last_obs,update_target_counter,  rng = runner_state\n",
    "\n",
    "            # SELECT ACTION\n",
    "            en_last_obs = encoder_state.apply_fn(encoder_state.params, last_obs)\n",
    "            rng, _rng = jax.random.split(rng)\n",
    "            pi, value = train_state.apply_fn(train_state.params, en_last_obs)\n",
    "            action = pi.sample(seed=_rng)\n",
    "            log_prob = pi.log_prob(action)\n",
    "\n",
    "            # STEP ENV\n",
    "            rng, _rng = jax.random.split(rng)\n",
    "            rng_step = jax.random.split(_rng, config[\"NUM_ENVS_PER_DEVICE\"])\n",
    "            obsv, env_state, reward, done, info = env.step(rng_step, env_state, action, env_params)\n",
    "\n",
    "            # INT REWARD\n",
    "            pred_in = (bt,en_last_obs[np.newaxis, :],action[np.newaxis, :])\n",
    "            pred_obs, bt, close_hstate, open_hstate = pred_state.apply_fn(pred_state.params, close_hstate,open_hstate, pred_in)\n",
    "            tar_obs = target.apply(target_params, obsv)\n",
    "            pred_norm = (pred_obs.squeeze(0)) / (jnp.linalg.norm(pred_obs.squeeze(0), axis=-1, keepdims=True))\n",
    "            tar_norm = jax.lax.stop_gradient(\n",
    "                (tar_obs) / (jnp.linalg.norm(tar_obs, axis=-1, keepdims=True))\n",
    "            )\n",
    "            int_reward = jnp.square(jnp.linalg.norm((pred_norm - tar_norm), axis=-1)) * (\n",
    "                1 - done\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            transition = Transition(done, action, value, reward, int_reward,log_prob, last_obs, obsv,info)\n",
    "            runner_state = (train_state,pred_state,encoder_state,target_params, close_hstate,open_hstate,bt, byol_reward_norm_params, env_state, obsv, update_target_counter,rng)\n",
    "            return runner_state, transition\n",
    "        \n",
    "        close_initial_hstate, open_initial_hstate, initial_bt= runner_state[4:7]\n",
    "        runner_state, traj_batch = jax.lax.scan(_env_step, runner_state, None, config[\"NUM_STEPS\"])\n",
    "\n",
    "        # CALCULATE ADVANTAGE\n",
    "        train_state,pred_state,encoder_state,target_params, close_hstate,open_hstate,bt, byol_reward_norm_params, env_state, last_obs, update_target_counter,rng = runner_state\n",
    "        update_target_counter+=1\n",
    "        en_last_obs = encoder_state.apply_fn(encoder_state.params, last_obs)\n",
    "        _, last_val = train_state.apply_fn(train_state.params, en_last_obs)\n",
    "\n",
    "        def _calculate_gae(traj_batch, last_val, byol_reward_norm_params):\n",
    "            prior_norm_int_reward, byol_reward_norm_params = byol_normlise_prior_int_rewards(traj_batch.int_reward,byol_reward_norm_params, config[\"REW_NORM_PARAMETER\"] )\n",
    "            norm_traj_batch = Transition(\n",
    "                traj_batch.done,\n",
    "                traj_batch.action,\n",
    "                traj_batch.value,\n",
    "                traj_batch.reward,\n",
    "                prior_norm_int_reward,\n",
    "                traj_batch.log_prob,\n",
    "                traj_batch.obs,\n",
    "                traj_batch.next_obs,\n",
    "                traj_batch.info,\n",
    "            )\n",
    "            def _get_advantages(gae_and_next_value, transition):\n",
    "                gae, next_value = gae_and_next_value\n",
    "                done, value, reward, int_reward = (\n",
    "                    transition.done,\n",
    "                    transition.value,\n",
    "                    transition.reward,\n",
    "                    transition.int_reward\n",
    "                )\n",
    "                delta = (reward+config[\"INT_LAMBDA\"]*int_reward) + config[\"GAMMA\"] * next_value * (1 - done) - value\n",
    "                gae = delta + config[\"GAMMA\"] * config[\"GAE_LAMBDA\"] * (1 - done) * gae\n",
    "                return (gae, value), gae\n",
    "\n",
    "            _, advantages = jax.lax.scan(\n",
    "                _get_advantages,\n",
    "                (jnp.zeros_like(last_val), last_val),\n",
    "                norm_traj_batch,\n",
    "                reverse=True,\n",
    "                unroll=16,\n",
    "            )\n",
    "            return advantages, advantages + traj_batch.value, prior_norm_int_reward, byol_reward_norm_params\n",
    "\n",
    "        advantages, targets, prior_norm_int_reward, byol_reward_norm_params = _calculate_gae(traj_batch, last_val, byol_reward_norm_params)\n",
    "\n",
    "        # UPDATE NETWORK\n",
    "        def _update_epoch(update_state, unused):\n",
    "            def _update_minbatch(train_states, batch_info):\n",
    "                traj_batch, advantages, targets,bt,close_hstate,open_hstate = batch_info\n",
    "                train_state, pred_state, encoder_state, target_params = train_states\n",
    "\n",
    "                def _pred_loss(pred_params, encoder_params, target_params, traj_batch , bt,close_hstate,open_hstate):\n",
    "                    en_last_obs = encoder_state.apply_fn(encoder_params, traj_batch.obs)\n",
    "                    # en_obs = encoder_state.apply_fn(encoder_params, traj_batch.next_obs)\n",
    "                    pred_in = (bt,en_last_obs,traj_batch.action)\n",
    "                    pred_obs, _,_,_= pred_state.apply_fn(pred_params, close_hstate[0],open_hstate[0], pred_in)\n",
    "                    tar_obs = target.apply(target_params, traj_batch.obs)\n",
    "                    pred_norm = (pred_obs) / (jnp.linalg.norm(pred_obs, axis=-1, keepdims=True))\n",
    "                    tar_norm = jax.lax.stop_gradient(\n",
    "                        (tar_obs) / (jnp.linalg.norm(tar_obs, axis=-1,keepdims=True))\n",
    "                    )\n",
    "                    loss = jnp.square(jnp.linalg.norm((pred_norm - tar_norm), axis=-1)) * (\n",
    "                        1 - traj_batch.done\n",
    "                    )\n",
    "                    return loss.mean()\n",
    "                \n",
    "                def _encoder_loss(train_params, encoder_params,traj_batch, gae, targets,pred_params, target_params, bt,close_hstate,open_hstate):\n",
    "                    rl_loss,_ = _loss_fn(train_params, encoder_params,traj_batch, gae, targets)\n",
    "                    pred_loss = _pred_loss(pred_params, encoder_params, target_params, traj_batch , bt,close_hstate,open_hstate)\n",
    "\n",
    "                    return rl_loss+pred_loss\n",
    "\n",
    "                def _loss_fn(train_params, encoder_params,traj_batch, gae, targets):\n",
    "                    # RERUN NETWORK\n",
    "                    en_last_obs = encoder_state.apply_fn(encoder_params, traj_batch.obs)\n",
    "                    pi, value = train_state.apply_fn(train_params, en_last_obs)\n",
    "                    log_prob = pi.log_prob(traj_batch.action)\n",
    "\n",
    "                    # CALCULATE VALUE LOSS\n",
    "                    value_pred_clipped = traj_batch.value + (value - traj_batch.value).clip(\n",
    "                        -config[\"CLIP_EPS\"], config[\"CLIP_EPS\"]\n",
    "                    )\n",
    "                    value_losses = jnp.square(value - targets)\n",
    "                    value_losses_clipped = jnp.square(value_pred_clipped - targets)\n",
    "                    value_loss = 0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n",
    "\n",
    "                    # CALCULATE ACTOR LOSS\n",
    "                    ratio = jnp.exp(log_prob - traj_batch.log_prob)\n",
    "                    gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
    "                    loss_actor1 = ratio * gae\n",
    "                    loss_actor2 = (\n",
    "                        jnp.clip(\n",
    "                            ratio,\n",
    "                            1.0 - config[\"CLIP_EPS\"],\n",
    "                            1.0 + config[\"CLIP_EPS\"],\n",
    "                        )\n",
    "                        * gae\n",
    "                    )\n",
    "                    loss_actor = -jnp.minimum(loss_actor1, loss_actor2)\n",
    "                    loss_actor = loss_actor.mean()\n",
    "                    entropy = pi.entropy().mean()\n",
    "\n",
    "                    total_loss = (\n",
    "                        loss_actor + config[\"VF_COEF\"] * value_loss - config[\"ENT_COEF\"] * entropy\n",
    "                    )\n",
    "                    return total_loss, (value_loss, loss_actor, entropy)\n",
    "\n",
    "                (loss, (vloss, aloss, entropy)), grads = jax.value_and_grad(_loss_fn, has_aux=True)(\n",
    "                    train_state.params, encoder_state.params, traj_batch, advantages, targets\n",
    "                )\n",
    "                pred_loss, pred_grads = jax.value_and_grad(_pred_loss)(pred_state.params, encoder_state.params, target_params, traj_batch , bt,close_hstate,open_hstate)\n",
    "                encoder_loss, encoder_grads = jax.value_and_grad(_encoder_loss,1)(train_state.params, encoder_state.params,traj_batch, advantages, targets,pred_state.params, target_params, bt,close_hstate,open_hstate)\n",
    "                (loss, vloss, aloss, entropy,pred_loss,encoder_loss, grads,pred_grads,encoder_grads) = jax.lax.pmean(\n",
    "                    (loss, vloss, aloss, entropy, pred_loss,encoder_loss, grads,pred_grads,encoder_grads), axis_name=\"devices\"\n",
    "                )\n",
    "                train_state = train_state.apply_gradients(grads=grads)\n",
    "                pred_state = pred_state.apply_gradients(grads=pred_grads)\n",
    "                encoder_state = encoder_state.apply_gradients(grads=encoder_grads)\n",
    "\n",
    "                def update_conditionally(update_target_counter, target_params, encoder_params):\n",
    "                    def true_fun(_):\n",
    "                        # Perform the EMA update\n",
    "                        return jax.tree_util.tree_map(\n",
    "                            lambda tp, op: tp * config[\"EMA_PARAMETER\"] + (1 - config[\"EMA_PARAMETER\"]) * op,\n",
    "                            target_params,\n",
    "                            encoder_params\n",
    "                        )\n",
    "\n",
    "                    def false_fun(_):\n",
    "                        # Return the old target_params unchanged\n",
    "                        return target_params\n",
    "\n",
    "                    # Conditionally update every 10 steps\n",
    "                    return jax.lax.cond(\n",
    "                        update_target_counter % 10 == 0,\n",
    "                        true_fun,\n",
    "                        false_fun,\n",
    "                        None  # The argument passed to true_fun and false_fun, `_` in this case is unused\n",
    "                    )\n",
    "\n",
    "                # Use this function in your update step, pass the appropriate parameters\n",
    "                target_params = update_conditionally(update_target_counter, target_params, encoder_state.params)\n",
    "\n",
    "\n",
    "                return (train_state,pred_state,encoder_state,target_params), (loss, (vloss, aloss, entropy), pred_loss, encoder_loss)\n",
    "\n",
    "            train_state,pred_state,encoder_state, target_params,bt, close_hstate,open_hstate, traj_batch, advantages, targets,update_target_counter, rng = update_state\n",
    "            rng, _rng = jax.random.split(rng)\n",
    "            permutation = jax.random.permutation(_rng, config[\"NUM_ENVS_PER_DEVICE\"])\n",
    "            batch = (traj_batch, advantages, targets, bt, close_hstate, open_hstate)\n",
    "\n",
    "            shuffled_batch = jax.tree_util.tree_map(\n",
    "                lambda x: jnp.take(x, permutation, axis=0), batch\n",
    "            )\n",
    "\n",
    "            minibatches = jax.tree_util.tree_map(\n",
    "                lambda x: jnp.swapaxes(\n",
    "                    jnp.reshape(\n",
    "                        x,\n",
    "                        [x.shape[0], config[\"NUM_MINIBATCHES\"], -1]\n",
    "                        + list(x.shape[2:]),\n",
    "                    ),\n",
    "                    1,\n",
    "                    0,\n",
    "                ),\n",
    "                shuffled_batch,\n",
    "            )\n",
    "\n",
    "            (train_state,pred_state,encoder_state,target_params), total_loss = jax.lax.scan(_update_minbatch, (train_state,pred_state,encoder_state,target_params), minibatches)\n",
    "            update_state = (train_state,pred_state,encoder_state, target_params,bt, close_hstate,open_hstate, traj_batch, advantages, targets, update_target_counter,rng)\n",
    "            return update_state, total_loss\n",
    "\n",
    "        update_state = (train_state,pred_state,encoder_state, target_params,initial_bt, close_initial_hstate[None, :],open_initial_hstate[None, :], traj_batch, advantages, targets, update_target_counter,rng)\n",
    "        update_state, loss_info = jax.lax.scan(\n",
    "            _update_epoch, update_state, None, config[\"UPDATE_EPOCHS\"]\n",
    "        )\n",
    "        train_state,pred_state, encoder_state, target_params = update_state[:4]\n",
    "        metric = traj_batch.info\n",
    "        rng = update_state[-1]\n",
    "        if config.get(\"DEBUG\"):\n",
    "\n",
    "            def callback(info):\n",
    "                return_values = info[\"returned_episode_returns\"][info[\"returned_episode\"]]\n",
    "                timesteps = (\n",
    "                    info[\"timestep\"][info[\"returned_episode\"]] * config[\"NUM_ENVS_PER_DEVICE\"]\n",
    "                )\n",
    "                for t in range(len(timesteps)):\n",
    "                    print(f\"global step={timesteps[t]}, episodic return={return_values[t]}\")\n",
    "\n",
    "            jax.debug.callback(callback, metric)\n",
    "\n",
    "        runner_state = (train_state,pred_state,encoder_state,target_params, close_hstate,open_hstate,bt, byol_reward_norm_params, env_state, last_obs,update_target_counter, rng)\n",
    "        return runner_state, (metric, loss_info,traj_batch.int_reward, prior_norm_int_reward)\n",
    "\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    runner_state = (train_state, pred_state,encoder_state,target_params, close_hstate,open_hstate,bt, byol_reward_norm_params,env_state, obsv,update_target_counter, _rng)\n",
    "    runner_state, extra_info = jax.lax.scan(_update_step, runner_state, None, config[\"NUM_UPDATES\"])\n",
    "    metric, rl_total_loss, int_reward, norm_int_reward = extra_info\n",
    "    return {\n",
    "        \"train_state\": runner_state[:3],\n",
    "        \"metrics\": metric,\n",
    "        \"rl_total_loss\": rl_total_loss[0],\n",
    "        \"rl_value_loss\": rl_total_loss[1][0],\n",
    "        \"rl_actor_loss\": rl_total_loss[1][1],\n",
    "        \"rl_entrophy_loss\": rl_total_loss[1][2],\n",
    "        \"pred_loss\": rl_total_loss[2],\n",
    "        \"encoder_loss\": rl_total_loss[3],\n",
    "        \"int_reward\":int_reward,\n",
    "        \"norm_int_reward\": norm_int_reward,\n",
    "        \"byol_reward_norm_params\":byol_reward_norm_params,\n",
    "        \"update_target_counter\": update_target_counter,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_values=jnp.array([ 000.1,0.01,0.1, 0.003,0.005,0.02,0.03,0.05,0.2,0.5]).sort()\n",
    "lambda_values=jnp.array([0.01]).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in Asterix-MinAtar\n",
      "Training in Asterix-MinAtar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "/home/batsy/MetaLearnCuriosity/tpu_curiosax/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_values = {}\n",
    "for lambda_value in lambda_values:\n",
    "    y_values[lambda_value] = {}  # Use float(lambda_value) to ensure dictionary keys are serializable\n",
    "    config[\"INT_LAMBDA\"]=lambda_value\n",
    "    for env_name in environments:\n",
    "        rng = jax.random.PRNGKey(config[\"SEED\"])\n",
    "        t = time.time()\n",
    "        config, env, env_params = make_config_env(config, env_name)\n",
    "        print(f\"Training in {config['ENV_NAME']}\")\n",
    "\n",
    "        if config[\"NUM_SEEDS\"] > 1:\n",
    "            rng = jax.random.split(rng, config[\"NUM_SEEDS\"])\n",
    "            rng, train_state,pred_state, encoder_state, target_params,close_init_hstate,open_init_hstate, init_bt = jax.jit(jax.vmap(ppo_make_train, out_axes=(1,0,0,0,0,0,0,0)))(rng)\n",
    "            open_init_hstate = replicate(open_init_hstate, jax.local_devices())\n",
    "            close_init_hstate = replicate(close_init_hstate, jax.local_devices())\n",
    "            train_state = replicate(train_state, jax.local_devices())\n",
    "            pred_state = replicate(pred_state, jax.local_devices())\n",
    "            encoder_state = replicate(encoder_state, jax.local_devices())\n",
    "            target_params = replicate(target_params, jax.local_devices())\n",
    "            init_bt = replicate(init_bt, jax.local_devices())\n",
    "            train_fn = jax.vmap(train)\n",
    "            train_fn = jax.pmap(train_fn, axis_name=\"devices\")\n",
    "            print(f\"Training in {config['ENV_NAME']}\")\n",
    "            t = time.time()\n",
    "            output = jax.block_until_ready(train_fn(rng, train_state, pred_state, encoder_state, target_params,close_init_hstate,open_init_hstate, init_bt ))\n",
    "            elapsed_time = time.time() - t\n",
    "\n",
    "\n",
    "        else:\n",
    "            rng, train_state,pred_state, encoder_state, target_params,close_init_hstate,open_init_hstate, init_bt  = ppo_make_train(rng)\n",
    "            open_init_hstate = replicate(open_init_hstate, jax.local_devices())\n",
    "            close_init_hstate = replicate(close_init_hstate, jax.local_devices())\n",
    "            train_state = replicate(train_state, jax.local_devices())\n",
    "            pred_state = replicate(pred_state, jax.local_devices())\n",
    "            encoder_state = replicate(encoder_state, jax.local_devices())\n",
    "            target_params = replicate(target_params, jax.local_devices())\n",
    "            init_bt = replicate(init_bt, jax.local_devices())\n",
    "            train_fn = jax.pmap(train, axis_name=\"devices\")\n",
    "            t = time.time()\n",
    "            output = jax.block_until_ready(train_fn(rng, train_state, pred_state, encoder_state, target_params,close_init_hstate,open_init_hstate, init_bt ))\n",
    "            elapsed_time = time.time() - t\n",
    "\n",
    "        print((time.time() - t)/60)\n",
    "        # Assuming `output` is your array\n",
    "        epi_ret = output[\"metrics\"][\"returned_episode_returns\"].mean(0).mean(0).mean(-1).reshape(-1)\n",
    "        int_rew = output[\"int_reward\"].mean(0).mean(0).mean(-1).reshape(-1)\n",
    "        int_norm_rew = output[\"norm_int_reward\"].mean(0).mean(0).mean(-1).reshape(-1)\n",
    "        pred_loss = unreplicate(output[\"pred_loss\"]).mean(-1).mean(0).mean(-1)\n",
    "        encoder_loss = unreplicate(output[\"encoder_loss\"]).mean(-1).mean(0).mean(-1)\n",
    "\n",
    "        # Use the last element of each row from 'epi_ret' as y-values\n",
    "        y_values[lambda_value][env_name] = (epi_ret,int_rew,int_norm_rew,pred_loss,encoder_loss)\n",
    "\n",
    "# Print or process `y_values` as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.       , 0.       , 0.       , ..., 0.3046875, 0.3125   ,\n",
       "       0.3125   ], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values[0.009999999776482582]['Asterix-MinAtar'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Metric names corresponding to the data stored in y_values\n",
    "metric_names = [\n",
    "    \"Episode Returns\",\n",
    "    \"Intrinsic Reward\",\n",
    "    \"Normalized Intrinsic Reward\",\n",
    "    \"Pred Loss\",\n",
    "    \"Encoder Loss\",\n",
    "]\n",
    "\n",
    "# Initialize plotting\n",
    "for env_name in environments:\n",
    "    num_metrics = len(metric_names)\n",
    "    fig, axs = plt.subplots(num_metrics, 1, figsize=(12, 6 * num_metrics), sharex=True)\n",
    "    fig.suptitle(f'Training Metrics Over Time for {env_name}')\n",
    "\n",
    "    # Iterate over each metric\n",
    "    for idx, metric_name in enumerate(metric_names):\n",
    "        ax = axs[idx] if num_metrics > 1 else axs\n",
    "\n",
    "        # Plot each lambda's data for this metric\n",
    "        plotted = False\n",
    "        for lambda_value in lambda_values:\n",
    "            lambda_key = float(lambda_value)  # Ensure float key matches dictionary keys\n",
    "            if lambda_key in y_values and env_name in y_values[lambda_key]:\n",
    "                metric_data = y_values[lambda_key][env_name][idx]\n",
    "                if len(metric_data) > 0:\n",
    "                    x_axis = range(len(metric_data))\n",
    "                    ax.plot(x_axis, metric_data, label=f'Lambda={lambda_value:.2f}')\n",
    "                    plotted = True\n",
    "\n",
    "        # Only add a legend if data was actually plotted\n",
    "        if plotted:\n",
    "            ax.set_title(metric_name)\n",
    "            ax.set_xlabel(\"Training Steps\")\n",
    "            ax.set_ylabel(metric_name)\n",
    "            ax.legend()\n",
    "        else:\n",
    "            ax.set_title(f\"{metric_name} (no data)\")\n",
    "            ax.set_xlabel(\"Training Steps\")\n",
    "            ax.set_ylabel(metric_name)\n",
    "\n",
    "    # Adjust layout and save the figure\n",
    "    plt.subplots_adjust(hspace=0.4)  # Adjust vertical spacing between plots\n",
    "    plt.savefig(f\"{env_name}_metrics_over_time.png\")\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize plotting\n",
    "for env_name in environments:\n",
    "    # Prepare data for plotting\n",
    "    final_returns = []\n",
    "    labels = []\n",
    "\n",
    "    # Collect final episode returns for each lambda value\n",
    "    for lambda_value in lambda_values:\n",
    "        lambda_key = float(lambda_value)  # Ensure float key matches dictionary keys\n",
    "        if lambda_key in y_values and env_name in y_values[lambda_key]:\n",
    "            epi_returns = y_values[lambda_key][env_name][0]  # Assuming index 0 is Episode Returns\n",
    "            if len(epi_returns) > 0:\n",
    "                final_returns.append(epi_returns[-1])  # Get the last value\n",
    "                labels.append(f'Lambda={lambda_value:.2f}')\n",
    "\n",
    "    # Plotting\n",
    "    if final_returns:  # Check if there are any final returns to plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(labels, final_returns, color='skyblue')\n",
    "        plt.title(f'Final Episode Returns vs. Lambda for {env_name}')\n",
    "        plt.xlabel('Lambda Value')\n",
    "        plt.ylabel('Final Episode Return')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{env_name}_final_episode_returns_vs_lambda.png\")\n",
    "        plt.close()  # Close the plot to free up memory\n",
    "    else:\n",
    "        print(f\"No final episode return data available for {env_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_values[0.009999999776482582]['Asterix-MinAtar'][4])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpu_curiosax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
